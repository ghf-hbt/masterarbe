import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt

# ================== 配置参数 ==================
CFG = {
    "img_size": 256,         # 输入图像尺寸
    "n_classes": 2,          # 分割类别数（含背景）
    "batch_size": 4,         # 根据显存调整
    "lr": 1e-3,              # 学习率
    "epochs": 20,            # 训练轮次
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "data_paths": {
        "train_img": "train_images",
        "train_mask": "train_masks",
        "val_img": "val_images",    # 可选
        "val_mask": "val_masks"     # 可选
    }
}

# ================== 数据集类 ==================
class SegDataset(Dataset):
    def __init__(self, img_dir, mask_dir, transform=None):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.transform = transform
        self.filenames = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.filenames[idx])
        mask_name = self.filenames[idx].split('.')[0] + '_mask.png'
        mask_path = os.path.join(self.mask_dir, mask_name)
        
        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')  # 转为灰度图
        
        if self.transform:
            image = self.transform(image)
            mask = self.transform(mask)
        
        mask = torch.clamp(mask * 255, 0, self.cfg["n_classes"]-1).long()  # 确保mask值在类别范围内
        return image, mask.squeeze()

# ================== U-Net模型 ==================
class UNet(nn.Module):
    def __init__(self, in_ch=3, out_ch=2):
        super().__init__()
        
        def conv_block(in_ch, out_ch):
            return nn.Sequential(
              nn.Conv2d(in_ch, out_ch, 3, padding=1),
              nn.BatchNorm2d(out_ch),
              nn.ReLU(),
              nn.Conv2d(out_ch, out_ch, 3, padding=1),
              nn.BatchNorm2d(out_ch),
              nn.ReLU(),
              # 添加残差连接
              nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity(),
              nn.ReLU()
            )
             
        # 编码器
        self.down1 = conv_block(in_ch, 64)
        self.down2 = conv_block(64, 128)
        self.down3 = conv_block(128, 256)
        self.pool = nn.MaxPool2d(2)
        
        # 中间层
        self.bridge = conv_block(256, 512)
        
        # 解码器
        self.up1 = nn.Sequential( 
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(512, 256, 3, padding=1) 
        )
        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.conv2 = conv_block(256, 128)
        self.up3 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.conv3 = conv_block(128, 64)
        
        # 输出层
        self.out = nn.Conv2d(64, out_ch, 1)

    def forward(self, x):
        # 编码
        c1 = self.down1(x)       # [64, H, W]
        p1 = self.pool(c1)
        c2 = self.down2(p1)      # [128, H/2, W/2]
        p2 = self.pool(c2)
        c3 = self.down3(p2)      # [256, H/4, W/4]
        p3 = self.pool(c3)
        
        # 中间层
        bridge = self.bridge(p3) # [512, H/8, W/8]
        
        # 解码
        u1 = self.up1(bridge)    # [256, H/4, W/4]
        merge1 = torch.cat([u1, c3], dim=1)
        c4 = self.conv1(merge1)
        
        u2 = self.up2(c4)        # [128, H/2, W/2]
        merge2 = torch.cat([u2, c2], dim=1)
        c5 = self.conv2(merge2)
        
        u3 = self.up3(c5)        # [64, H, W]
        merge3 = torch.cat([u3, c1], dim=1)
        c6 = self.conv3(merge3)
        
        return self.out(c6)      # [n_classes, H, W]

# ================== 训练流程 ==================
def train():
    # 数据预处理
    transform = transforms.Compose([
        transforms.Resize((CFG["img_size"], CFG["img_size"])),
        transforms.ToTensor()
    ])
    
    # 加载数据集
    train_set = SegDataset(
        CFG["data_paths"]["train_img"],
        CFG["data_paths"]["train_mask"],
        transform
    )
    train_loader = DataLoader(train_set, CFG["batch_size"], shuffle=True)
    
    # 初始化模型
    model = UNet(in_ch=3, out_ch=CFG["n_classes"]).to(CFG["device"])
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=CFG["lr"])
    
    # 训练循环
    for epoch in range(CFG["epochs"]):
        model.train()
        running_loss = 0.0
        
        for images, masks in train_loader:
            images = images.to(CFG["device"])
            masks = masks.to(CFG["device"])
            
            # 前向传播
            outputs = model(images)
            loss = criterion(outputs, masks)
            
            # 反向传播
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
        
        print(f"Epoch {epoch+1}/{CFG['epochs']}, Loss: {running_loss/len(train_loader):.4f}")
    
    # 保存模型
    torch.save(model.state_dict(), "unet_model.pth")
    print("Training complete! Model saved.")

# ================== 推理与可视化 ==================
def predict(img_path, model_path="unet_model.pth"):
    # 加载模型
    model = UNet(in_ch=3, out_ch=CFG["n_classes"]).to(CFG["device"])
    model.load_state_dict(torch.load(model_path))
    model.eval()
    
    # 预处理图像
    transform = transforms.Compose([
        transforms.Resize((CFG["img_size"], CFG["img_size"])),
        transforms.ToTensor()
    ])
    
    image = Image.open(img_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0).to(CFG["device"])
    
    # 预测
    with torch.no_grad():
        output = model(image_tensor)
        pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()
    
    # 可视化
    plt.figure(figsize=(12,6))
    plt.subplot(1,2,1)
    plt.imshow(image)
    plt.title("Input Image")
    plt.axis('off')
    
    plt.subplot(1,2,2)
    plt.imshow(pred, cmap='jet')
    plt.title("Prediction")
    plt.axis('off')
    plt.show()

# ================== 执行训练 ==================
if __name__ == "__main__":
    train()
    # 使用示例：
    # predict("your_image.jpg")